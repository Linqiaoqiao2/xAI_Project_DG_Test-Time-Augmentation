# src/dataset/pacs_loader.py

import os
import json
import random
from PIL import Image
from torch.utils.data import Dataset, DataLoader, random_split
from torchvision.datasets import ImageFolder

class PACSFromSplit(Dataset):
    def __init__(self, split_file, split_type='train', transform=None):
        """
        Args:
            split_file: path to .json file generated by pacs_preprocessing.py
            split_type: one of 'train', 'val', or 'val_source'
            transform: torchvision transforms
        """
        with open(split_file, "r") as f:
            split_data = json.load(f)

        self.samples = split_data[split_type]
        self.transform = transform

    def __len__(self):
        return len(self.samples)

    def __getitem__(self, idx):
        path = self.samples[idx]["img"]
        label = self.samples[idx]["label"]
        image = Image.open(path).convert("RGB")
        if self.transform:
            image = self.transform(image)
        return image, label

class SimpleImageDataset(Dataset):
    def __init__(self, image_paths, labels, transform):
        self.image_paths = image_paths
        self.labels = labels
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image = Image.open(self.image_paths[idx]).convert("RGB")
        if self.transform:
            image = self.transform(image)
        return image, self.labels[idx]

def get_pacs_dataloaders(
    dataset_root,
    source_domains,
    target_domain,
    categories,
    val_split,
    batch_size,
    num_workers,
    train_transform,
    test_transform,
    seed=42
):
    random.seed(seed)

    def load_domain(domain, label_map):
        domain_path = os.path.join(dataset_root, domain)
        samples = []
        for label_idx, cat in enumerate(label_map):
            class_dir = os.path.join(domain_path, cat)
            for fname in os.listdir(class_dir):
                if fname.endswith(".jpg"):
                    samples.append({"img": os.path.join(class_dir, fname), "label": label_idx})
        return samples

    label_map = categories
    all_source_samples = []
    for domain in source_domains:
        all_source_samples.extend(load_domain(domain, label_map))

    # === Split source into train / val_source ===
    train_samples, val_source_samples = train_test_split(
        all_source_samples, test_size=val_split, random_state=seed, stratify=[s["label"] for s in all_source_samples]
    )

    # === Target test domain ===
    test_samples = load_domain(target_domain, label_map)

    train_dataset = PACSFromList(train_samples, transform=train_transform)
    val_dataset = PACSFromList(val_source_samples, transform=test_transform)
    test_dataset = PACSFromList(test_samples, transform=test_transform)

    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=num_workers)
    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)
    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers)

    return train_loader, val_loader, test_loader