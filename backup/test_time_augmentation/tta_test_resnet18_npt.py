# -*- coding: utf-8 -*-
"""resnet18_no_pretrained_TTA(test).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y225e9Z5bwFgYaSqKo3GqjAnKZkLTEhO
"""

#!/usr/bin/env python
# coding: utf-8
"""
PACS Test-Time Augmentation (TTA) Evaluation Script â€” with MultiViewPredictor (MVDG)
"""

# ===============================
# Imports
# ===============================
import os, json, zipfile
from datetime import datetime
from pathlib import Path
from typing import List

import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from PIL import Image
from tqdm import tqdm
import matplotlib.pyplot as plt

from google.colab import drive

# ===============================
# Configuration
# ===============================
GOOGLE_DRIVE_FILE_PATH = Path("/content/drive/MyDrive/Colab Notebooks/PACS.zip")
COLAB_ZIP_NAME = "PACS.zip"
DATASET_ROOT  = Path("/content/kfold")     # adjust if your unzip folder differs
MODEL_DIR     = Path("/content/drive/MyDrive/xAi_dg/baseline_unpretrained_results/models")

PACS_DOMAINS    = ["art_painting", "cartoon", "photo", "sketch"]
PACS_CATEGORIES = ["dog", "elephant", "giraffe", "guitar", "horse", "house", "person"]
SEEDS           = [42, 123, 2024]
STRATEGIES      = ["baseline", "alexnet", "custom", "MVDG"]

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ===============================
# Mount Drive and Unpack Dataset
# ===============================
print("ðŸ“‚ Mounting Google Drive â€¦")
drive.mount("/content/drive", force_remount=True)
print("ðŸ“¥ Copying dataset ZIP from Drive â€¦")
os.system(f"cp '{GOOGLE_DRIVE_FILE_PATH}' {COLAB_ZIP_NAME}")

if not DATASET_ROOT.exists():
    print("ðŸ“¦ Unpacking dataset ZIP â€¦")
    with zipfile.ZipFile(COLAB_ZIP_NAME, "r") as zip_ref:
        zip_ref.extractall("/content")      # keep consistent with DATASET_ROOT
else:
    print("âœ… Dataset already unpacked â€” skipping extraction")

# ===============================
# Dataset Definition
# ===============================
class TTADataset(Dataset):
    """Read image paths & labels only; augmentations are applied later."""
    def __init__(self, base_path: Path, domain: str, categories: List[str], transform=None):
        self.image_paths, self.labels = [], []
        self.transform = transform
        for label_idx, category in enumerate(categories):
            folder = base_path / domain / category
            if not folder.is_dir():
                continue
            for file in folder.iterdir():
                if file.suffix.lower() in {".jpg", ".jpeg", ".png"}:
                    self.image_paths.append(file)
                    self.labels.append(label_idx)

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img   = Image.open(self.image_paths[idx]).convert("RGB")
        label = self.labels[idx]
        return (self.transform(img) if self.transform else img), label

# ===============================
# Model
# ===============================
def get_resnet18(num_classes: int = 7, pretrained: bool = False):
    weights = models.ResNet18_Weights.IMAGENET1K_V1 if pretrained else None
    model   = models.resnet18(weights=weights)
    model.fc = nn.Linear(model.fc.in_features, num_classes)
    return model

# ===============================
# MultiViewPredictor (MVDG)
# ===============================
class MultiViewPredictor:
    """Random multi-view inference (MVDG)."""
    def __init__(self, model, device='cuda', t: int = 32):
        self.model  = model.to(device)
        self.device = device
        self.t      = t
        self.transform = transforms.Compose([
            transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                 std =[0.229, 0.224, 0.225]),
        ])

    def predict_logits(self, image: Image.Image):
        self.model.eval()
        image = image.convert("RGB")
        # ensure dtype matches model (important for AMP / mixed precision)
        dtype = next(self.model.parameters()).dtype
        logits_sum = torch.zeros(self.model.fc.out_features,
                                 device=self.device,
                                 dtype=dtype)
        with torch.no_grad():
            for _ in range(self.t):
                aug_img = self.transform(image).unsqueeze(0).to(self.device)
                logits  = self.model(aug_img)
                logits_sum += logits.squeeze(0)
        return logits_sum / self.t

    def predict_label(self, image: Image.Image):
        return torch.argmax(self.predict_logits(image)).item()

# ===============================
# TTA Wrapper
# ===============================
class TTAWrapper:
    def __init__(self, model, device=DEVICE):
        self.model  = model.to(device)
        self.device = device
        self.mean   = [0.485, 0.456, 0.406]
        self.std    = [0.229, 0.224, 0.225]
        self.normalize = transforms.Normalize(self.mean, self.std)

    # ---------- Transforms for each strategy ----------
    def get_transforms(self, strategy: str):
        if strategy == "baseline":
            return [transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                self.normalize
            ])]

        if strategy == "alexnet":
            # TenCrop -> stack once to (10,3,224,224)
            def _ten_crop(img):
                crops = transforms.TenCrop(224)(img)          # tuple len 10
                crops = [self.normalize(transforms.ToTensor()(c)) for c in crops]
                return torch.stack(crops)                     # (10,3,224,224)

            return [transforms.Compose([
                transforms.Resize(256),
                transforms.Lambda(_ten_crop)
            ])]

        if strategy == "custom":
            return [
                transforms.Compose([
                    transforms.Resize((224, 224)),
                    transforms.ToTensor(),
                    self.normalize
                ]),
                transforms.Compose([
                    transforms.Resize((224, 224)),
                    transforms.RandomHorizontalFlip(p=1.0),
                    transforms.ToTensor(),
                    self.normalize
                ]),
                transforms.Compose([
                    transforms.Resize((224, 224)),
                    transforms.RandomRotation(degrees=15),
                    transforms.ToTensor(),
                    self.normalize
                ])
            ]
        raise ValueError(f" Unsupported strategy: {strategy}")

    # ---------- Batch prediction ----------
    def predict_batch(self, images_pil_list, strategy: str):
        if strategy == "MVDG":
            predictor = MultiViewPredictor(self.model, device=self.device, t=32)
            preds = torch.tensor(
                [predictor.predict_label(img) for img in images_pil_list],
                device=self.device,
                dtype=torch.long
            )
            return preds

        logits_per_transform = []
        for t in self.get_transforms(strategy):
            outs = [t(img) for img in images_pil_list]

            if strategy == "alexnet":
                # outs shape: (B,10,3,224,224)
                batch_tensor = torch.stack(outs).to(self.device)
                B, N, C, H, W = batch_tensor.shape
                logits = self.model(batch_tensor.view(B * N, C, H, W))
                logits = logits.view(B, N, -1).mean(1)        # average over 10 crops
            else:
                batch_tensor = torch.stack(outs).to(self.device)
                logits = self.model(batch_tensor)

            logits_per_transform.append(torch.softmax(logits, dim=1))

        avg_logits = torch.stack(logits_per_transform).mean(0)
        return avg_logits.argmax(1)

    # ---------- Evaluate an entire DataLoader ----------
    def evaluate_loader(self, dataloader, strategy: str):
        correct = total = 0
        self.model.eval()
        for images, labels in tqdm(dataloader, desc=f"TTA [{strategy}]"):
            labels = labels.to(self.device)
            preds  = self.predict_batch(images, strategy)
            correct += (preds == labels).sum().item()
            total   += labels.size(0)
        return correct / total

# ===============================
# Collate Function
# ===============================
def pil_collate_fn(batch):
    images, labels = zip(*batch)
    return list(images), torch.tensor(labels, dtype=torch.long)

# ===============================
# Main Evaluation Loop
# ===============================
results, avg_results = {}, {}
for domain in PACS_DOMAINS:
    results[domain], avg_results[domain] = {}, {}
    for strategy in STRATEGIES:
        accs = []
        for seed in SEEDS:
            model_path = MODEL_DIR / f"best_model_seed{seed}_target_{domain}.pth"
            assert model_path.is_file(), f" Missing: {model_path}"
            print(f"\n===== Domain: {domain} | Seed: {seed} | Strategy: {strategy} =====")
            model = get_resnet18(len(PACS_CATEGORIES), pretrained=False)
            model.load_state_dict(torch.load(model_path, map_location=DEVICE))
            loader = DataLoader(
                TTADataset(DATASET_ROOT, domain, PACS_CATEGORIES),
                batch_size=32,
                shuffle=False,
                num_workers=0,               # set to 0 if you encounter multiprocessing errors
                collate_fn=pil_collate_fn
            )
            tta  = TTAWrapper(model)
            acc  = tta.evaluate_loader(loader, strategy)
            print(f" â†’ Acc: {acc:.4f}")
            results[domain].setdefault(f"seed_{seed}", {})[strategy] = acc
            accs.append(acc)
        avg_results[domain][strategy] = sum(accs) / len(accs)
        print(f" Avg Acc [{domain}] [{strategy}] = {avg_results[domain][strategy]:.4f}")

# ===============================
# Save Results
# ===============================
now = datetime.now().strftime("%Y%m%d_%H%M%S")
save_dir = Path(f"/content/drive/MyDrive/xAi_dg/TestTimeAugmentation/TTA_results_{now}")
save_dir.mkdir(parents=True, exist_ok=True)
with open(save_dir / "TTA_results.json", "w") as f:
    json.dump({"per_seed": results, "averaged": avg_results}, f, indent=4)

# ===============================
# Plot
# ===============================
plt.figure(figsize=(10, 6))
# ensure tensor is on CPU before converting to numpy
x = torch.arange(len(PACS_DOMAINS), device="cpu").numpy()
width = 0.13
for i, strategy in enumerate(STRATEGIES):
    plt.bar(x + i * width,
            [avg_results[d][strategy] for d in PACS_DOMAINS],
            width=width,
            label=strategy)
plt.ylabel("Avg Accuracy")
plt.title("PACS â€” TTA (3 seeds)")
plt.xticks(x + width * (len(STRATEGIES) - 1) / 2, PACS_DOMAINS)
plt.legend()
plt.grid(axis="y")
plt.tight_layout()
plt.savefig(save_dir / "TTA_accuracy_plot.png")
plt.show()

print(f"ðŸ“Š All results saved to: {save_dir}")

