# -*- coding: utf-8 -*-
"""resnet50_no_pretrained_TTA(test).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YVDv0yxX4WXnZgXY8RoD-VROnyAQD-CN
"""

#!/usr/bin/env python
# coding: utf-8
"""
PACS Test-Time Augmentation (TTA) Evaluation Script — with MultiViewPredictor (MVDG)
Optimized Version (Fixed OOM Issues)
"""

import os, json, zipfile, gc
from datetime import datetime
from pathlib import Path
from typing import List

import torch
from torch import nn
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms, models
from PIL import Image
from tqdm import tqdm
import matplotlib.pyplot as plt

from google.colab import drive

# ===============================
# Configuration
# ===============================
GOOGLE_DRIVE_FILE_PATH = Path("/content/drive/MyDrive/Colab Notebooks/PACS.zip")
COLAB_ZIP_NAME = "PACS.zip"
DATASET_ROOT  = Path("/content/kfold")
MODEL_DIR     = Path("/content/drive/MyDrive/xAi_dg/baseline_unpretrained50_results/models")

PACS_DOMAINS    = ["art_painting", "cartoon", "photo", "sketch"]
PACS_CATEGORIES = ["dog", "elephant", "giraffe", "guitar", "horse", "house", "person"]
SEEDS           = [42, 123, 2024]
STRATEGIES      = ["baseline", "alexnet", "custom", "MVDG"]

DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
torch.backends.cudnn.benchmark = False

# ===============================
# Mount Drive and Unpack Dataset
# ===============================
print("\U0001F4C2 Mounting Google Drive …")
drive.mount("/content/drive", force_remount=True)
print("\U0001F4E5 Copying dataset ZIP from Drive …")
os.system(f"cp '{GOOGLE_DRIVE_FILE_PATH}' {COLAB_ZIP_NAME}")

if not DATASET_ROOT.exists():
    print("\U0001F4E6 Unpacking dataset ZIP …")
    with zipfile.ZipFile(COLAB_ZIP_NAME, "r") as zip_ref:
        zip_ref.extractall("/content")
else:
    print(" Dataset already unpacked — skipping extraction")

# ===============================
# Dataset Definition
# ===============================
class TTADataset(Dataset):
    def __init__(self, base_path: Path, domain: str, categories: List[str], transform=None):
        self.image_paths, self.labels = [], []
        self.transform = transform
        for label_idx, category in enumerate(categories):
            folder = base_path / domain / category
            if not folder.is_dir():
                continue
            for file in folder.iterdir():
                if file.suffix.lower() in {".jpg", ".jpeg", ".png"}:
                    self.image_paths.append(file)
                    self.labels.append(label_idx)

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        img   = Image.open(self.image_paths[idx]).convert("RGB")
        label = self.labels[idx]
        return (self.transform(img) if self.transform else img), label

# ===============================
# Model
# ===============================
def get_resnet50(num_classes: int = 7, pretrained: bool = False):
    weights = models.ResNet50_Weights.IMAGENET1K_V1 if pretrained else None
    model   = models.resnet50(weights=weights)
    model.fc = nn.Linear(model.fc.in_features, num_classes)
    return model

# ===============================
# MultiViewPredictor (MVDG)
# ===============================
class MultiViewPredictor:
    def __init__(self, model, device='cuda', t: int = 32):
        self.model  = model.to(device)
        self.device = device
        self.t      = t
        self.transform = transforms.Compose([
            transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
            transforms.RandomHorizontalFlip(),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ])

    def predict_logits(self, image: Image.Image):
        self.model.eval()
        image = image.convert("RGB")
        dtype = next(self.model.parameters()).dtype
        logits_sum = torch.zeros(self.model.fc.out_features, device=self.device, dtype=dtype)
        with torch.no_grad():
            for _ in range(self.t):
                aug_img = self.transform(image).unsqueeze(0).to(self.device)
                logits  = self.model(aug_img)
                logits_sum += logits.squeeze(0)
        return logits_sum / self.t

    def predict_label(self, image: Image.Image):
        return torch.argmax(self.predict_logits(image)).item()

# ===============================
# TTA Wrapper
# ===============================
class TTAWrapper:
    def __init__(self, model, device=DEVICE):
        self.model  = model.to(device)
        self.device = device
        self.mean   = [0.485, 0.456, 0.406]
        self.std    = [0.229, 0.224, 0.225]
        self.normalize = transforms.Normalize(self.mean, self.std)

    def get_transforms(self, strategy: str):
        if strategy == "baseline":
            return [transforms.Compose([
                transforms.Resize((224, 224)),
                transforms.ToTensor(),
                self.normalize
            ])]

        if strategy == "alexnet":
            def _ten_crop(img):
                crops = transforms.TenCrop(224)(img)
                crops = [self.normalize(transforms.ToTensor()(c)) for c in crops]
                return torch.stack(crops)
            return [transforms.Compose([
                transforms.Resize(256),
                transforms.Lambda(_ten_crop)
            ])]

        if strategy == "custom":
            return [
                transforms.Compose([
                    transforms.Resize((224, 224)),
                    transforms.ToTensor(),
                    self.normalize
                ]),
                transforms.Compose([
                    transforms.Resize((224, 224)),
                    transforms.RandomHorizontalFlip(p=1.0),
                    transforms.ToTensor(),
                    self.normalize
                ]),
                transforms.Compose([
                    transforms.Resize((224, 224)),
                    transforms.RandomRotation(degrees=15),
                    transforms.ToTensor(),
                    self.normalize
                ])
            ]
        raise ValueError(f" Unsupported strategy: {strategy}")

    def predict_batch(self, images_pil_list, strategy: str):
        if strategy == "MVDG":
            predictor = MultiViewPredictor(self.model, device=self.device, t=16)
            preds = []
            with torch.no_grad():
                for img in images_pil_list:
                    pred = predictor.predict_label(img)
                    preds.append(pred)
            return torch.tensor(preds, device=self.device, dtype=torch.long)

        logits_per_transform = []
        transforms_list = self.get_transforms(strategy)
        for transform in transforms_list:
            outs = [transform(img) for img in images_pil_list]
            batch_tensor = torch.stack(outs).to(self.device)

            if strategy == "alexnet":
                B, N, C, H, W = batch_tensor.shape
                logits = self.model(batch_tensor.view(B * N, C, H, W))
                logits = logits.view(B, N, -1).mean(1)
            else:
                logits = self.model(batch_tensor)

            logits_per_transform.append(torch.softmax(logits, dim=1))

        avg_logits = torch.stack(logits_per_transform).mean(0)
        return avg_logits.argmax(1)

    def evaluate_loader(self, dataloader, strategy: str):
        correct = total = 0
        self.model.eval()
        for images, labels in tqdm(dataloader, desc=f"TTA [{strategy}]"):
            labels = labels.to(self.device)
            preds  = self.predict_batch(images, strategy)
            correct += (preds == labels).sum().item()
            total   += labels.size(0)
        return correct / total

# ===============================
# Collate Function
# ===============================
def pil_collate_fn(batch):
    images, labels = zip(*batch)
    return list(images), torch.tensor(labels, dtype=torch.long)

# ===============================
# Main Evaluation Loop
# ===============================
results, avg_results = {}, {}
for domain in PACS_DOMAINS:
    results[domain], avg_results[domain] = {}, {}
    for strategy in STRATEGIES:
        accs = []
        for seed in SEEDS:
            gc.collect()
            torch.cuda.empty_cache()
            model_path = MODEL_DIR / f"best_model_seed{seed}_target_{domain}.pth"
            assert model_path.is_file(), f"❌ Missing: {model_path}"
            print(f"\n===== Domain: {domain} | Seed: {seed} | Strategy: {strategy} =====")
            model = get_resnet50(len(PACS_CATEGORIES), pretrained=False)
            model.load_state_dict(torch.load(model_path, map_location=DEVICE))

            loader = DataLoader(
                TTADataset(DATASET_ROOT, domain, PACS_CATEGORIES),
                batch_size=2,
                shuffle=False,
                num_workers=0,
                collate_fn=pil_collate_fn
            )
            tta  = TTAWrapper(model)
            acc  = tta.evaluate_loader(loader, strategy)
            print(f" → Acc: {acc:.4f}")
            results[domain].setdefault(f"seed_{seed}", {})[strategy] = acc
            accs.append(acc)
        avg_results[domain][strategy] = sum(accs) / len(accs)
        print(f"Avg Acc [{domain}] [{strategy}] = {avg_results[domain][strategy]:.4f}")

# ===============================
# Save Results
# ===============================
now = datetime.now().strftime("%Y%m%d_%H%M%S")
save_dir = Path(f"/content/drive/MyDrive/xAi_dg/resnet50_no_pretrained_TestTimeAug/TTAug_results_{now}")
save_dir.mkdir(parents=True, exist_ok=True)
with open(save_dir / "TTA_results.json", "w") as f:
    json.dump({"per_seed": results, "averaged": avg_results}, f, indent=4)

plt.figure(figsize=(10, 6))
x = torch.arange(len(PACS_DOMAINS), device="cpu").numpy()
width = 0.13
for i, strategy in enumerate(STRATEGIES):
    plt.bar(x + i * width, [avg_results[d][strategy] for d in PACS_DOMAINS], width=width, label=strategy)
plt.ylabel("Avg Accuracy")
plt.title("PACS — TTA (3 seeds)")
plt.xticks(x + width * (len(STRATEGIES) - 1) / 2, PACS_DOMAINS)
plt.legend()
plt.grid(axis="y")
plt.tight_layout()
plt.savefig(save_dir / "TTA_accuracy_plot.png")
plt.show()

print(f"\U0001F4CA All results saved to: {save_dir}")

