# -*- coding: utf-8 -*-
"""baseline_resnet50_no_pretrained.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v0kCNzW6fFXZnjOfRd0Zbu-tsh1ULqhr
"""

# âœ… å¯¼å…¥ç›¸å…³åº“
import os, json, random, zipfile
from pathlib import Path

import numpy as np
from PIL import Image
from tqdm import tqdm

import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import models, transforms
from torch.utils.data import DataLoader, Dataset
from sklearn.model_selection import train_test_split
from google.colab import drive

# âœ… Colab æ–‡ä»¶è·¯å¾„ä¸æŒ‚è½½é…ç½®
GOOGLE_DRIVE_FILE_PATH = "/content/drive/MyDrive/Colab Notebooks/PACS.zip"
COLAB_ZIP_NAME = "PACS.zip"
BASE_PACS_PATH = "kfold"

# âœ… æŒ‚è½½ Google Drive
print("\nâœ… æŒ‚è½½ Google Drive")
drive.mount('/content/drive', force_remount=True)

# âœ… è§£å‹ PACS æ•°æ®é›†
os.system(f"cp '{GOOGLE_DRIVE_FILE_PATH}' {COLAB_ZIP_NAME}")
with zipfile.ZipFile(COLAB_ZIP_NAME, 'r') as zip_ref:
    zip_ref.extractall(".")
print(f"Dataset base path is configured as: '{BASE_PACS_PATH}'")

# âœ… wandb é…ç½®
USE_WANDB = True
if USE_WANDB:
    import wandb

# âœ… è®¾å¤‡é€‰æ‹©
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {DEVICE}")

# âœ… éšæœºç§å­è®¾ç½®
def set_global_seed(seed: int):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if DEVICE.type == "cuda":
        torch.cuda.manual_seed_all(seed)

def worker_init_fn(worker_id):
    worker_seed = torch.initial_seed() % 2**32
    np.random.seed(worker_seed)
    random.seed(worker_seed)

def get_torch_generator(seed: int):
    g = torch.Generator()
    g.manual_seed(seed)
    return g

# âœ… PACS æ•°æ®é›†é…ç½®
PACS_DOMAINS = ["art_painting", "cartoon", "photo", "sketch"]
PACS_CATEGORIES = ["dog", "elephant", "giraffe", "guitar", "horse", "house", "person"]

# âœ… è®­ç»ƒè¶…å‚æ•°
MODEL_CHOICE = "resnet50"
PRETRAINED = False
NUM_EPOCHS = 40
BATCH_SIZE = 32
LEARNING_RATE = 1e-3
PATIENCE = 5
SEEDS = [42, 2024, 123]

# âœ… æ¨¡å‹ä¸æ—¥å¿—å­˜å‚¨è·¯å¾„
SAVE_ROOT = "/content/drive/MyDrive/xAi_dg/baseline_unpretrained50_results/models"
Path(SAVE_ROOT).mkdir(parents=True, exist_ok=True)

# âœ… æ•°æ®é›†ç±»
class PACS_Dataset(Dataset):
    def __init__(self, base_path, domain_name, categories, transform=None):
        self.transform = transform
        self.image_paths, self.labels = [], []
        for idx, cat in enumerate(categories):
            cat_path = Path(base_path) / domain_name / cat
            if not cat_path.is_dir(): continue
            for img_file in cat_path.iterdir():
                if img_file.suffix.lower() in {".jpg", ".jpeg", ".png"}:
                    self.image_paths.append(str(img_file))
                    self.labels.append(idx)

    def __len__(self): return len(self.image_paths)

    def __getitem__(self, idx):
        img = Image.open(self.image_paths[idx]).convert("RGB")
        if self.transform: img = self.transform(img)
        return img, self.labels[idx]

class SimpleImageDataset(Dataset):
    def __init__(self, paths, labels, transform=None):
        self.paths, self.labels, self.transform = paths, labels, transform
    def __len__(self): return len(self.paths)
    def __getitem__(self, idx):
        img = Image.open(self.paths[idx]).convert("RGB")
        if self.transform: img = self.transform(img)
        return img, self.labels[idx]

# âœ… æ•°æ®å¢å¼º
mean, std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]
train_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean, std),
])
val_test_transform = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean, std),
])

# âœ… ResNet50 æ¨¡å‹å®šä¹‰
def get_model(num_classes=len(PACS_CATEGORIES), pretrained: bool = False):
    weights = "IMAGENET1K_V1" if pretrained else None
    model = models.resnet50(weights=weights)
    model.fc = nn.Linear(model.fc.in_features, num_classes)
    return model

# âœ… å•ä¸ª epoch è®­ç»ƒå’ŒéªŒè¯é€»è¾‘
def train_one_epoch(model, loader, criterion, optimizer):
    model.train()
    running_loss, correct, total = 0.0, 0, 0
    for x, y in loader:
        x, y = x.to(DEVICE), y.to(DEVICE)
        optimizer.zero_grad()
        outputs = model(x)
        loss = criterion(outputs, y)
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * x.size(0)
        correct += (outputs.argmax(1) == y).sum().item()
        total += y.size(0)
    return running_loss / total, correct / total

def eval_one_epoch(model, loader, criterion):
    model.eval()
    running_loss, correct, total = 0.0, 0, 0
    with torch.no_grad():
        for x, y in loader:
            x, y = x.to(DEVICE), y.to(DEVICE)
            outputs = model(x)
            loss = criterion(outputs, y)
            running_loss += loss.item() * x.size(0)
            correct += (outputs.argmax(1) == y).sum().item()
            total += y.size(0)
    return running_loss / total, correct / total

# âœ… ä¸»è®­ç»ƒæµç¨‹
if __name__ == "__main__":
    all_seed_results = []

    for seed in SEEDS:
        set_global_seed(seed)
        seed_results = []

        for target_domain in PACS_DOMAINS:
            print(f"\n=== Seed {seed} | Target Domain: {target_domain} ===")
            source_domains = [d for d in PACS_DOMAINS if d != target_domain]

            # âœ… å…¨å±€ class åˆ†å±‚åˆ‡åˆ†æ•°æ®é›†ï¼ˆglobal splitï¼‰
            domain_paths, domain_labels = [], []
            for d in source_domains:
                ds = PACS_Dataset(BASE_PACS_PATH, d, PACS_CATEGORIES)
                domain_paths.extend(ds.image_paths)
                domain_labels.extend(ds.labels)

            train_paths, val_paths, train_labels, val_labels = train_test_split(
                domain_paths,
                domain_labels,
                test_size=0.15,
                random_state=seed,
                stratify=domain_labels
            )

            g = get_torch_generator(seed)
            train_dataset = SimpleImageDataset(train_paths, train_labels, train_transform)
            val_dataset = SimpleImageDataset(val_paths, val_labels, val_test_transform)
            test_dataset = PACS_Dataset(BASE_PACS_PATH, target_domain, PACS_CATEGORIES, val_test_transform)

            train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2, pin_memory=True, worker_init_fn=worker_init_fn, generator=g)
            val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)
            test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2, pin_memory=True)

            run_prefix = f"seed{seed}_target_{target_domain}"
            log_path = Path(SAVE_ROOT) / f"log_{run_prefix}.json"
            checkpoint_path = Path(SAVE_ROOT) / f"checkpoint_{run_prefix}.pth"
            best_model_path = Path(SAVE_ROOT) / f"best_model_{run_prefix}.pth"

            # âœ… Resume æˆ–é‡æ–°è®­ç»ƒé€»è¾‘
            if log_path.exists():
                with open(log_path) as f:
                    log_data = json.load(f)
                finished = log_data.get("finished", False)
            else:
                log_data, finished = None, False

            if finished and best_model_path.exists():
                print(f"âœ… Finished log & best model found â†’ skip training, load test acc from best_model.")
                model = get_model().to(DEVICE)
                model.load_state_dict(torch.load(best_model_path, map_location=DEVICE))
                _, best_test_acc = eval_one_epoch(model, test_loader, nn.CrossEntropyLoss())
                seed_results.append(best_test_acc)
                continue

            if checkpoint_path.exists():
                print(f"ğŸ”„ Checkpoint found â†’ resume training from checkpoint.")
                checkpoint = torch.load(checkpoint_path, map_location=DEVICE)
                model = get_model().to(DEVICE)
                model.load_state_dict(checkpoint["model_state_dict"])
                optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)
                optimizer.load_state_dict(checkpoint["optimizer_state_dict"])
                start_epoch = checkpoint["epoch"] + 1
                best_val_acc = checkpoint["best_val_acc"]
                patience_counter = checkpoint.get("patience_counter", 0)
                epoch_log = checkpoint.get("epoch_log", [])
            else:
                print(f"ğŸŸ¢ No valid checkpoint/log found â†’ start training from scratch.")
                model = get_model(pretrained=PRETRAINED).to(DEVICE)
                optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)
                start_epoch, best_val_acc, patience_counter, epoch_log = 1, 0.0, 0, []

            if USE_WANDB:
                wandb_run = wandb.init(
                    project="PACS_ResNet18_Baseline",
                    name=f"Seed{seed}_Src2Tar_{'+'.join(source_domains)}â†’{target_domain}",
                    config={"epochs": NUM_EPOCHS, "batch_size": BATCH_SIZE, "learning_rate": LEARNING_RATE, "model": MODEL_CHOICE, "seed": seed, "target_domain": target_domain},
                    reinit=True,
                )

            criterion = nn.CrossEntropyLoss()

            # âœ… è®­ç»ƒä¸»å¾ªç¯
            for epoch in range(start_epoch, NUM_EPOCHS + 1):
                train_loss, train_acc = train_one_epoch(model, train_loader, criterion, optimizer)
                val_loss, val_acc = eval_one_epoch(model, val_loader, criterion)
                print(f"Epoch {epoch}/{NUM_EPOCHS} train_acc={train_acc:.3f} val_acc={val_acc:.3f}")

                epoch_log.append({"epoch": epoch, "train_loss": train_loss, "train_acc": train_acc, "val_loss": val_loss, "val_acc": val_acc})
                if USE_WANDB:
                    wandb.log({"epoch": epoch, "train/loss": train_loss, "train/acc": train_acc, "val/loss": val_loss, "val/acc": val_acc})

                if val_acc > best_val_acc:
                    best_val_acc, patience_counter = val_acc, 0
                    torch.save(model.state_dict(), best_model_path)
                else:
                    patience_counter += 1

                torch.save({"epoch": epoch, "model_state_dict": model.state_dict(), "optimizer_state_dict": optimizer.state_dict(), "best_val_acc": best_val_acc, "patience_counter": patience_counter, "epoch_log": epoch_log}, checkpoint_path)

                if patience_counter >= PATIENCE:
                    print("Early stopping triggered!")
                    break

            # âœ… æœ€ç»ˆæµ‹è¯•è¯„ä¼°
            model.load_state_dict(torch.load(best_model_path, map_location=DEVICE))
            test_loss, test_acc = eval_one_epoch(model, test_loader, criterion)
            print(f"ğŸ¯ Final target-domain ({target_domain}) accuracy: {test_acc:.3f}")

            log_data = {"seed": seed, "target_domain": target_domain, "epochs": epoch_log, "best_val_acc": best_val_acc, "best_test_acc": test_acc, "finished": True}
            with open(log_path, "w") as f:
                json.dump(log_data, f, indent=2)

            seed_results.append(test_acc)
            if USE_WANDB:
                try:
                    wandb_run.summary["best_val_acc"] = best_val_acc
                    wandb_run.summary["test_acc"] = test_acc
                    wandb.finish()
                except Exception as e:
                    print(f"âš ï¸ WandB finish failed: {e}")

        all_seed_results.append(seed_results)

    # âœ… ç»“æœç»Ÿè®¡
    mean_accuracies = np.mean(all_seed_results, axis=0).tolist()
    final_results = {"seeds": SEEDS, "domains": PACS_DOMAINS, "accuracies_per_seed_domain": all_seed_results, "mean_accuracies": mean_accuracies, "average_overall": float(np.mean(mean_accuracies)), "worst_case_overall": float(np.min(mean_accuracies))}
    with open(Path(SAVE_ROOT) / "baseline_results_multi_seed.json", "w") as f:
        json.dump(final_results, f, indent=2)
    print("\nâœ… Training finished for all seeds! Results saved.")